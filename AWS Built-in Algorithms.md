# Amazon Built-in Algorithms
The following table lists parameters for each of the algorithms provided by Amazon SageMaker.

|Algorithm name                                |Channel name                                                                                       |Training input mode|File type                                                    |Instance class                                               |Parallelizable                                      |
|----------------------------------------------|---------------------------------------------------------------------------------------------------|-------------------|-------------------------------------------------------------|-------------------------------------------------------------|----------------------------------------------------|
|AutoGluon-Tabular                             |training and (optionally) validation                                                               |File               |CSV                                                          |CPU or GPU (single instance only)                            |No                                                  |
|BlazingText                                   |train                                                                                              |File or Pipe       |Text file (one sentence per line with space-separated tokens)|CPU or GPU (single instance only)                            |No                                                  |
|CatBoost                                      |training and (optionally) validation                                                               |File               |CSV                                                          |CPU (single instance only)                                   |No                                                  |
|DeepAR Forecasting                            |train and (optionally) test                                                                        |File               |JSON Lines or Parquet                                        |CPU or GPU                                                   |Yes                                                 |
|Factorization Machines                        |train and (optionally) test                                                                        |File or Pipe       |recordIO-protobuf                                            |CPU (GPU for dense data)                                     |Yes                                                 |
|Image Classification - MXNet                  |train and validation, (optionally) train_lst, validation_lst, and model                            |File or Pipe       |recordIO or image files (.jpg or .png)                       |GPU                                                          |Yes                                                 |
|Image Classification - TensorFlow             |training and validation                                                                            |File               |image files (.jpg, .jpeg, or .png)                           |CPU or GPU                                                   |Yes (only across multiple GPUs on a single instance)|
|IP Insights                                   |train and (optionally) validation                                                                  |File               |CSV                                                          |CPU or GPU                                                   |Yes                                                 |
|K-Means                                       |train and (optionally) test                                                                        |File or Pipe       |recordIO-protobuf or CSV                                     |CPU or GPUCommon (single GPU device on one or more instances)|No                                                  |
|K-Nearest-Neighbors (k-NN)                    |train and (optionally) test                                                                        |File or Pipe       |recordIO-protobuf or CSV                                     |CPU or GPU (single GPU device on one or more instances)      |Yes                                                 |
|LDA                                           |train and (optionally) test                                                                        |File or Pipe       |recordIO-protobuf or CSV                                     |CPU (single instance only)                                   |No                                                  |
|LightGBM                                      |train/training and (optionally) validation                                                         |File               |CSV                                                          |CPU                                                          |Yes                                                 |
|Linear Learner                                |train and (optionally) validation, test, or both                                                   |File or Pipe       |recordIO-protobuf or CSV                                     |CPU or GPU                                                   |Yes                                                 |
|Neural Topic Model                            |train and (optionally) validation, test, or both                                                   |File or Pipe       |recordIO-protobuf or CSV                                     |CPU or GPU                                                   |Yes                                                 |
|Object2Vec                                    |train and (optionally) validation, test, or both                                                   |File               |JSON Lines                                                   |CPU or GPU (single instance only)                            |No                                                  |
|Object Detection - MXNet                      |train and validation, (optionally) train_annotation, validation_annotation, and model              |File or Pipe       |recordIO or image files (.jpg or .png)                       |GPU                                                          |Yes                                                 |
|Object Detection - TensorFlow                 |training and validation                                                                            |File               |image files (.jpg, .jpeg, or .png)                           |GPU                                                          |Yes (only across multiple GPUs on a single instance)|
|PCA                                           |train and (optionally) test                                                                        |File or Pipe       |recordIO-protobuf or CSV                                     |CPU or GPU                                                   |Yes                                                 |
|Random Cut Forest                             |train and (optionally) test                                                                        |File or Pipe       |recordIO-protobuf or CSV                                     |CPU                                                          |Yes                                                 |
|Semantic Segmentation                         |train and validation, train_annotation, validation_annotation, and (optionally) label_map and model|File or Pipe       |Image files                                                  |GPU (single instance only)                                   |No                                                  |
|Seq2Seq Modeling                              |train, validation, and vocab                                                                       |File               |recordIO-protobuf                                            |GPU (single instance only)                                   |No                                                  |
|TabTransformer                                |training and (optionally) validation                                                               |File               |CSV                                                          |CPU or GPU (single instance only)                            |No                                                  |
|Text Classification - TensorFlow              |training and validation                                                                            |File               |CSV                                                          |CPU or GPU                                                   |Yes (only across multiple GPUs on a single instance)|
|XGBoost (0.90-1, 0.90-2, 1.0-1, 1.2-1, 1.2-21)|train and (optionally) validation                                                                  |File or Pipe       |CSV, LibSVM, or Parquet                                      |CPU (or GPU for 1.2-1)                                       |Yes                                                 |


## ContentTypes for Built-in Algorithms

|ContentType                                                                                                            |Algorithm                                        |
|-----------------------------------------------------------------------------------------------------------------------|-------------------------------------------------|
|application/x-image                                                                                                    |Object Detection Algorithm, Semantic Segmentation|
|application/x-recordio                                                                                                 |Object Detection Algorithm                       |
|application/x-recordio-protobuf                                                                                        |Factorization Machines, K-Means, k-NN, Latent Dirichlet Allocation, Linear Learner, NTM, PCA, RCF, Sequence-to-Sequence|
|application/jsonlines                                                                                                  |BlazingText, DeepAR                              |
|image/jpeg                                                                                                             |Object Detection Algorithm, Semantic Segmentation|
|image/png                                                                                                              |Object Detection Algorithm, Semantic Segmentation|
|text/csv                                                                                                               |IP Insights, K-Means, k-NN, Latent Dirichlet Allocation, Linear Learner, NTM, PCA, RCF, XGBoost|
|text/libsvm                                                                                                            |XGBoost                                          |


## Tabular
Amazon SageMaker provides built-in algorithms that are tailored to the analysis of tabular data. Tabular data refers to any datasets that are organized in tables consisting of rows (observations) and columns (features). The built-in SageMaker algorithms for tabular data can be used for either classification or regression problems.

### AutoGluon
AutoGluon-Tabular is a popular open-source AutoML framework that trains highly accurate machine learning models on an unprocessed tabular dataset. Unlike existing AutoML frameworks that primarily focus on model and hyperparameter selection, AutoGluon-Tabular succeeds by ensembling multiple models and stacking them in multiple layers.

AutoGluon-Tabular performs advanced data processing, deep learning, and multi-layer model ensemble methods. It automatically recognizes the data type in each column for robust data preprocessing, including special handling of text fields.

AutoGluon fits various models ranging from off-the-shelf boosted trees to customized neural networks. These models are ensembled in a novel way: models are stacked in multiple layers and trained in a layer-wise manner that guarantees raw data can be translated into high-quality predictions within a given time constraint. This process mitigates overfitting by splitting the data in various ways with careful tracking of out-of-fold examples.

The AutoGluon-Tabular algorithm performs well in machine learning competitions because of its robust handling of a variety of data types, relationships, and distributions. You can use AutoGluon-Tabular for regression, classification (binary and multiclass), and ranking problems.

Please find the demo example [here](https://github.com/ankitakotadiya/Data-Engineering-ML/blob/main/SageMaker-Buit-in-Algorithms/Amazon_Tabular_Regression_AutoGluon.ipynb).


### CatBoost
CatBoost is a popular and high-performance open-source implementation of the Gradient Boosting Decision Tree (GBDT) algorithm. GBDT is a supervised learning algorithm that attempts to accurately predict a target variable by combining an ensemble of estimates from a set of simpler and weaker models.

You can find the example [here](https://github.com/ankitakotadiya/Data-Engineering-ML/blob/main/SageMaker-Buit-in-Algorithms/Amazon_Tabular_Regression_LightGBM_CatBoost.ipynb).

|Parameter Name       |Description                                                                                                                                                                                                                                                                                                                                                                                                   |
|---------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
|iterations           |The maximum number of trees that can be built. Default value: 500.                                                                                                                                                                                                                                                                                                                                            |
|early_stopping_rounds|The training will stop if one metric of one validation data point does not improve in the last early_stopping_rounds round. If early_stopping_rounds is less than or equal to zero, this hyperparameter is ignored. Default value: 5.                                                                                                                                                                         |
|eval_metric          |The evaluation metric for validation data. If eval_metric is set to the default "auto" value, then the algorithm automatically chooses an evaluation metric based on the type of classification problem: "RMSE" for regression "AUC" for binary classification "MultiClass" for multi-class classification. Valid values: string, refer to the CatBoost documentation for valid values. Default value: "auto".|
|learning_rate        |The rate at which the model weights are updated after working through each batch of training examples. Valid values: float, range: (0.0, 1.0). Default value: 0.009.                                                                                                                                                                                                                                          |
|depth                |Depth of the tree. Valid values: integer, range: (1, 16). Default value: 6.                                                                                                                                                                                                                                                                                                                                   |
|l2_leaf_reg          |Coefficient for the L2 regularization term of the cost function. Default value: 3.                                                                                                                                                                                                                                                                                                                            |
|random_strength      |The amount of randomness to use for scoring splits when the tree structure is selected. Use this parameter to avoid overfitting the model. Default value: 1.0.                                                                                                                                                                                                                                                |
|max_leaves           |The maximum number of leaves in the resulting tree. Can only be used with the "Lossguide" growing policy. Valid values: integer, range: [2, 64]. Default value: 31.                                                                                                                                                                                                                                           |
|rsm                  |Random subspace method. The percentage of features to use at each split selection, when features are selected over again at random. Valid values: float, range: (0.0, 1.0]. Default value: 1.0.                                                                                                                                                                                                               |
|sampling_frequency   |Frequency to sample weights and objects when building trees. Valid values: string, either: ("PerTreeLevel" or "PerTree"). Default value: "PerTreeLevel".                                                                                                                                                                                                                                                      |
|min_data_in_leaf     |The minimum number of training samples in a leaf. CatBoost does not search for new splits in leaves with a sample count less than the specified value. Can only be used with the "Lossguide" and "Depthwise" growing policies. Valid values: integer, range: (1 or âˆž). Default value: 1.                                                                                                                      |
|bagging_temperature  |Defines the settings of the Bayesian bootstrap. Use the Bayesian bootstrap to assign random weights to objects. If bagging_temperature is set to 1.0, then the weights are sampled from an exponential distribution. If bagging_temperature is set to 0.0, then all weights are 1.0. Default value: 1.0.                                                                                                      |
|boosting_type        | The boosting scheme. "Auto" means that the boosting_type is selected based on processing unit type, the number of objects in the training dataset, and the selected learning mode. Valid values: string, any of the following: ("Auto", "Ordered", "Plain"). Default value: "Auto".                                                                                                                          |
|scale_pos_weight     |The weight for positive class in binary classification. The value is used as a multiplier for the weights of objects from positive class. Default value: 1.0.                                                                                                                                                                                                                                                 |
|max_bin              |The number of splits for numerical features. "Auto" means that max_bin is selected based on the processing unit type and other parameters. For details, see the CatBoost documentation. Valid values: string, either: ("Auto" or string of integer from "1" to "65535" inclusively). Default value: "Auto".                                                                                                   |
|grow_policy          |The tree growing policy. Defines how to perform greedy tree construction. Valid values: string, any of the following: ("SymmetricTree", "Depthwise", or "Lossguide"). Default value: "SymmetricTree".                                                                                                                                                                                                         |
|random_seed          |The random seed used for training. Default value: 1.0.                                                                                                                                                                                                                                                                                                                                                        |
|thread_count         |The number of threads to use during the training. If thread_count is -1, then the number of threads is equal to the number of processor cores. thread_count cannot be 0. Valid values: integer, either: (-1 or positive integer). Default value: -1.                                                                                                                                                          |
|verbose              |The verbosity of print messages, with higher levels corresponding to more detailed print statements. Default value: 1.  


### Factorization Machines Algorithm
The Factorization Machines algorithm is a general-purpose supervised learning algorithm that you can use for both classification and regression tasks. It is an extension of a linear model that is designed to capture interactions between features within high dimensional sparse datasets economically. For example, in a click prediction system, the Factorization Machines model can capture click rate patterns observed when ads from a certain ad-category are placed on pages from a certain page-category. Factorization machines are a good choice for tasks dealing with high dimensional sparse datasets, such as click prediction and item recommendation.

The Amazon SageMaker Factorization Machines algorithm is highly scalable and can train across distributed instances. We recommend training and inference with CPU instances for both sparse and dense datasets. In some circumstances, training with one or more GPUs on dense data might provide some benefit. Training with GPUs is available only on dense data. Use CPU instances for sparse data. The Factorization Machines algorithm supports P2, P3, G4dn, and G5 instances for training and inference.

|Parameter Name       |Description                                                                                                                                                                                                                                                                                                                                                                                                   |
|---------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
|feature_dim(*)       |The dimension of the input feature space. This could be very high with sparse input. Valid values: Positive integer. Suggested value range: [10000,10000000]                                                                                                                                                                                                                                                  |
|num_factors(*)       |The dimensionality of factorization. Valid values: Positive integer. Suggested value range: [2,1000], 64 typically generates good outcomes and is a good starting point.                                                                                                                                                                                                                                      |
|predictor_type(*)    |The type of predictor. binary_classifier: For binary classification tasks. regressor: For regression tasks. Valid values: String: binary_classifier or regressor                                                                                                                                                                                                                                              |
|bias_init_method     |The initialization method for the bias term: normal: Initializes weights with random values sampled from a normal distribution with a mean of zero and standard deviation specified by bias_init_sigma. uniform: Initializes weights with random values uniformly sampled from a range specified by [-bias_init_scale, +bias_init_scale]. constant: Initializes the weights to a scalar value specified by bias_init_value. Valid values: uniform, normal, or constant Default value: normal|
|bias_init_scale      |Range for initialization of the bias term. Takes effect if bias_init_method is set to uniform. Valid values: Non-negative float. Suggested value range: [1e-8, 512]. Default value: None                                                                                                                                                                                                                      |
|bias_init_sigma      |The standard deviation for initialization of the bias term. Takes effect if bias_init_method is set to normal. Valid values: Non-negative float. Suggested value range: [1e-8, 512]. Default value: 0.01                                                                                                                                                                                                      |
|bias_init_value      |The initial value of the bias term. Takes effect if bias_init_method is set to constant. Valid values: Float. Suggested value range: [1e-8, 512]. Default value: None                                                                                                                                                                                                                                         |
|bias_lr              |The learning rate for the bias term. Valid values: Non-negative float. Suggested value range: [1e-8, 512]. Default value: 0.1                                                                                                                                                                                                                                                                                 |
|bias_wd              |The weight decay for the bias term. Valid values: Non-negative float. Suggested value range: [1e-8, 512]. Default value: 0.01                                                                                                                                                                                                                                                                                 |
|clip_gradient        |Gradient clipping optimizer parameter. Clips the gradient by projecting onto the interval [-clip_gradient, +clip_gradient]. Default value: None                                                                                                                                                                                                                                                               |
|epochs               |The number of training epochs to run. Default value: 1                                                                                                                                                                                                                                                                                                                                                        |
|eps                  |Epsilon parameter to avoid division by 0. Valid values: Float. Suggested value: small. Default value: None                                                                                                                                                                                                                                                                                                    |
|factors_init_method  |The initialization method for factorization terms: Valid values: uniform, normal, or constant. Default value: normal                                                                                                                                                                                                                                                                                          |
|factors_init_scale   |The range for initialization of factorization terms. Takes effect if factors_init_method is set to uniform. Valid values: Non-negative float. Suggested value range: [1e-8, 512]. Default value: None                                                                                                                                                                                                         |
|factors_init_sigma   |The standard deviation for initialization of factorization terms. Takes effect if factors_init_method is set to normal. Valid values: Non-negative float. Suggested value range: [1e-8, 512]. Default value: 0.001                                                                                                                                                                                            |
|factors_init_value   |The initial value of factorization terms. Takes effect if factors_init_method is set to constant. Valid values: Float. Suggested value range: [1e-8, 512]. Default value: None                                                                                                                                                                                                                                |
|factors_lr           |The learning rate for factorization terms. Valid values: Non-negative float. Suggested value range: [1e-8, 512]. Default value: 0.0001                                                                                                                                                                                                                                                                        |
|factors_wd           |The weight decay for factorization terms. Valid values: Non-negative float. Suggested value range: [1e-8, 512]. Default value: 0.00001                                                                                                                                                                                                                                                                        |
|linear_lr            |The learning rate for linear terms. Valid values: Non-negative float. Suggested value range: [1e-8, 512]. Default value: 0.001                                                                                                                                                                                                                                                                                |
|linear_init_method   |The initialization method for linear terms: Valid values: uniform, normal, or constant. Default value: normal                                                                                                                                                                                                                                                                                                 |
|linear_init_scale    |Range for initialization of linear terms. Takes effect if linear_init_method is set to uniform. Valid values: Non-negative float. Suggested value range: [1e-8, 512]. Default value: None                                                                                                                                                                                                                     |
|linear_init_sigma    |The standard deviation for initialization of linear terms. Takes effect if linear_init_method is set to normal. Default value: 0.01                                                                                                                                                                                                                                                                           |
|linear_init_value    |The initial value of linear terms. Takes effect if linear_init_method is set to constant. Default value: None                                                                                                                                                                                                                                                                                                 |
|linear_wd The weight decay for linear terms. Valid values: Non-negative float. Suggested value range: [1e-8, 512]. Default value: 0.001|                                                                                                                                                                                                                                                                                                                                                                                                              |
|mini_batch_size      |The size of mini-batch used for training. Default value: 1000                                                                                                                                                                                                                                                                                                                                                 |
|rescale_grad         |Gradient rescaling optimizer parameter. If set, multiplies the gradient with rescale_grad before updating. Often choose to be 1.0/batch_size. Default value: None                                                                                                                                                                                                                                             |

You can tune the following hyperparameters for the Factorization Machines algorithm. The initialization parameters that contain the terms bias, linear, and factorization depend on their initialization method. There are three initialization methods: uniform, normal, and constant. These initialization methods are not themselves tunable. The parameters that are tunable are dependent on this choice of the initialization method. For example, if the initialization method is uniform, then only the scale parameters are tunable. Specifically, if bias_init_method==uniform, then bias_init_scale, linear_init_scale, and factors_init_scale are tunable. Similarly, if the initialization method is normal, then only sigma parameters are tunable. If the initialization method is constant, then only value parameters are tunable. These dependencies are listed in the following table.

Please find the demo example [here](https://github.com/ankitakotadiya/Data-Engineering-ML/blob/main/SageMaker-Buit-in-Algorithms/factorization_machines_mnist.ipynb).


